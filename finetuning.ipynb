{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6ed459",
   "metadata": {},
   "source": [
    "# Fine-tuning Template Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b03a320-3ea2-4453-a81d-fe853a970f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean out stale wheels/caches\n",
    "!pip cache purge -q\n",
    "!rm -rf ~/.cache/torch_extensions\n",
    "\n",
    "# Ensure specific versions of bnb, torch for compatibility\n",
    "!pip uninstall -y torch torchvision torchaudio bitsandbytes\n",
    "!pip install --index-url https://download.pytorch.org/whl/cu121 \\\n",
    "  torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n",
    "\n",
    "!pip install bitsandbytes==0.45.0 triton==3.0.0 peft==0.12.0 accelerate==0.34.2 transformers==4.45.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b9182-1fa1-447f-995d-76a8a4682f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, bitsandbytes as bnb, peft, transformers, triton\n",
    "print(\"torch\", torch.__version__)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(\"transformers\", transformers.__version__)\n",
    "print(\"bnb\", bnb.__version__)\n",
    "print(\"peft\", peft.__version__)\n",
    "print(\"triton\", triton.__version__)\n",
    "print(\"CUDA?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727a8bf-8355-4c2f-9a12-8ebcb31383dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitsandbytes.optim import AdamW8bit\n",
    "import datetime as dt\n",
    "import inspect\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import platform\n",
    "import re\n",
    "import subprocess\n",
    "import time\n",
    "import boto3\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datasets import Audio, Dataset, DatasetDict, IterableDataset, load_dataset, load_from_disk, concatenate_datasets\n",
    "from jiwer import wer\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    AdaLoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    WhisperProcessor,\n",
    "    WhisperTokenizer,\n",
    "    WhisperFeatureExtractor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    get_scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7893bb82-1cb0-45e5-b33e-c3cbb02e8ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cache for Sagemaker to fetch processed clips\n",
    "EFS_CACHE = \"/mnt/custom-file-systems/efs/fs-05e9c5047118066bb_fsap-0b12f9aa4c66d5d46/hf_cache\"\n",
    "os.environ[\"HF_HOME\"] = EFS_CACHE\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = os.path.join(EFS_CACHE, \"datasets\")\n",
    "os.environ[\"HF_HUB_CACHE\"] = os.path.join(EFS_CACHE, \"hub\")\n",
    "os.environ[\"TORCH_HOME\"] = os.path.join(EFS_CACHE, \"torch\")\n",
    "os.environ[\"HF_HUB_DOWNLOAD_TMP\"] = os.path.join(EFS_CACHE, \"tmp\")\n",
    "\n",
    "os.makedirs(os.environ[\"HF_HUB_DOWNLOAD_TMP\"], exist_ok=True)\n",
    "print(\"Hugging Face cache now points to EFS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06acefb9-9f18-4756-926a-42183e55ccc7",
   "metadata": {},
   "source": [
    "### Project Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a22a57-4099-46a9-a26f-2348e663bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Config\n",
    "BUCKET = \"asrelder-data\"\n",
    "CLIPS_PREFIX = \"common_voice/23/cv-corpus-23.0-2025-09-05/en/clips/\"\n",
    "BASE_S3_PREFIX = f\"s3://{BUCKET}/{CLIPS_PREFIX}\"\n",
    "\n",
    "# Keys\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"FILL_ME_IN\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"FILL_ME_IN\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"FILL_ME_IN\"\n",
    "\n",
    "# Confirm\n",
    "!aws sts get-caller-identity\n",
    "\n",
    "# Test\n",
    "sts = boto3.client(\"sts\")\n",
    "print(sts.get_caller_identity())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c6d900-7421-412d-b342-5030cbb87bd4",
   "metadata": {},
   "source": [
    "### Download the train, validation, and test CSVs from GDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93d47e-c9d8-4f27-ab04-235f18038ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get csvs from GDrive\n",
    "DRIVE_FILE_IDS = {\n",
    "    \"train\": \"1AdCeMxDcE4rxqWSyPsfEh7TaS5dWjXD5\",  # common_voices_23_balanced_on_60.csv\n",
    "    \"val\": \"1GzrujHvGwA7MA9awtQI4IFRQIdYcLiBO\",  # common_voices_23_val_full.csv\n",
    "    \"test\": \"1bSjhB8WTDZWBTuppB-vU56AgOEzNNAeN\",  # common_voices_23_test_full.csv\n",
    "}\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "def download_from_drive(name, file_id):\n",
    "    out_path = f\"data/{name}.csv\"\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    print(f\"Downloading {name} split from Google Drive → {out_path}\")\n",
    "    subprocess.run([\"gdown\", \"--fuzzy\", url, \"-O\", out_path], check=True)\n",
    "    return out_path\n",
    "\n",
    "TRAIN_PATH = download_from_drive(\"train\", DRIVE_FILE_IDS[\"train\"])\n",
    "VAL_PATH = download_from_drive(\"val\", DRIVE_FILE_IDS[\"val\"])\n",
    "TEST_PATH = download_from_drive(\"test\", DRIVE_FILE_IDS[\"test\"])\n",
    "\n",
    "DATA_FILES = {\n",
    "    \"train\": TRAIN_PATH,\n",
    "    \"val\": VAL_PATH,\n",
    "    \"test\": TEST_PATH,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eb6883-fc3d-4a8d-91a4-8250eb306dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the columns for train, val, and test\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    path = f\"data/{split}.csv\"\n",
    "    df = pd.read_csv(path, nrows=1)\n",
    "    print(f\"{path} columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabb79d-277e-4ae7-8162-c1df48843086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add age_group for val and test (column present in train)\n",
    "def add_age_group_column(file_path: str):\n",
    "    \"\"\"\n",
    "    Adds 'age_group' column to the CSV file if missing\n",
    "    Derives it from the 'age' column (e.g., '23' -> '20')\n",
    "    NOTE: Modifies the file in place\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    if \"age_group\" in df.columns:\n",
    "        print(f\"Skipping, 'age_group' already exists in {file_path}\")\n",
    "        return\n",
    "\n",
    "    def infer_age_group(age_value):\n",
    "        if pd.isna(age_value):\n",
    "            return \"\"\n",
    "        # Normalize to string\n",
    "        s = str(age_value).strip().lower()\n",
    "        # Handle numeric (e.g. 23)\n",
    "        if re.match(r\"^\\d{2}$\", s):\n",
    "            decade = int(s) // 10 * 10\n",
    "            return f\"{decade}s\"\n",
    "        # Handle ranges like \"25-34\"\n",
    "        match = re.match(r\"(\\d{2})\\s*-\\s*(\\d{2})\", s)\n",
    "        if match:\n",
    "            decade = int(match.group(1)) // 10 * 10\n",
    "            return f\"{decade}s\"\n",
    "        # Handle words like 'twenties', 'forty', etc.\n",
    "        words_to_decade = {\n",
    "            \"teen\": \"10s\",\n",
    "            \"teens\": \"10s\",\n",
    "            \"twenty\": \"20s\",\n",
    "            \"twenties\": \"20s\",\n",
    "            \"thirty\": \"30s\",\n",
    "            \"thirties\": \"30s\",\n",
    "            \"forty\": \"40s\",\n",
    "            \"forties\": \"40s\",\n",
    "            \"fifty\": \"50s\",\n",
    "            \"fifties\": \"50s\",\n",
    "            \"sixty\": \"60s\",\n",
    "            \"sixties\": \"60s\",\n",
    "            \"seventy\": \"70s\",\n",
    "            \"seventies\": \"70s\",\n",
    "            \"eighty\": \"80s\",\n",
    "            \"eighties\": \"80s\",\n",
    "        }\n",
    "        for k, v in words_to_decade.items():\n",
    "            if k in s:\n",
    "                return v\n",
    "        return \"\"  # unknown or other format\n",
    "\n",
    "    df[\"age_group\"] = df[\"age\"].apply(infer_age_group)\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Added 'age_group' to {file_path} ({len(df)} rows)\")\n",
    "\n",
    "add_age_group_column(\"data/val.csv\")\n",
    "add_age_group_column(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f12b8b-95ea-47cf-b59b-c3a6ca973dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_s3_paths(file_path: str):\n",
    "    \"\"\"\n",
    "    Prepends full S3 URI prefix to the 'path' column\n",
    "    Modifies the file in place\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Processing {file_path} ({len(df)} rows)\")\n",
    "    if \"path\" in df.columns:\n",
    "        def prepend_prefix(p):\n",
    "            if isinstance(p, str) and not p.startswith(\"s3://\"):\n",
    "                return f\"{BASE_S3_PREFIX}/{p.lstrip('/')}\"\n",
    "            return p\n",
    "        df[\"path\"] = df[\"path\"].apply(prepend_prefix)\n",
    "        print(\"Updated 'path' column with S3 prefix\")\n",
    "\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Saved updated CSV: {file_path}\\n\")\n",
    "    print(f\"Updated 'path' for {file_path} ({len(df)} rows)\")\n",
    "\n",
    "# Apply to val/test (train likely already correct)\n",
    "add_s3_paths(\"data/train.csv\")\n",
    "add_s3_paths(\"data/val.csv\")\n",
    "add_s3_paths(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669aaa8d-d259-41b6-99a3-c2ec6c23ff88",
   "metadata": {},
   "source": [
    "### Load Whisper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d566d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper model + language/task settings\n",
    "WHISPER_MODEL = \"openai/whisper-base\"\n",
    "LANGUAGE = \"en\"\n",
    "TASK = \"transcribe\"\n",
    "\n",
    "# Compute and training\n",
    "GRADIENT_ACCUMULATION = 2\n",
    "BATCH_SIZE_PER_DEVICE = 4\n",
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 0.0001\n",
    "MAX_AUDIO_SECONDS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86148503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Utils\n",
    "# Detect SageMaker environment, map S3 paths\n",
    "\n",
    "def in_sagemaker() -> bool:\n",
    "    return any(k.startswith(\"SM_\") for k in os.environ.keys()) or os.environ.get(\"SAGEMAKER_JOB_NAME\") is not None\n",
    "\n",
    "def s3_join(*parts: str) -> str:\n",
    "    return \"/\".join([p.strip(\"/\").replace(\"s3://\",\"\") for p in parts])\n",
    "\n",
    "\n",
    "print(\"In SageMaker:\", in_sagemaker())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c47ce1-bdaa-4a8b-a95a-49284fbfb757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "def clean_numeric_columns(file_path: str, numeric_cols=(\"variant\", \"segment\")):\n",
    "    df = pd.read_csv(file_path)\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Cleaned {file_path}: non-numeric entries coerced to NaN.\")\n",
    "\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    clean_numeric_columns(f\"data/{split}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352726d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "STREAMING = False\n",
    "audio_col = \"path\"\n",
    "text_col = \"sentence\"\n",
    "if STREAMING:\n",
    "    print(\"Loading CSVs in streaming mode...\")\n",
    "else:\n",
    "    print(\"Loading CSVs into memory...\")\n",
    "raw_datasets = load_dataset(\"csv\", data_files=DATA_FILES, streaming=STREAMING)\n",
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d2124-3f28-48e3-a187-ebec8bdf6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use half of available CPUs\n",
    "print(f\"CPU count: {os.cpu_count()}\")\n",
    "NUM_PROC = max(1, os.cpu_count() // 2)\n",
    "print(f\"NUM_PROC: {NUM_PROC}\")\n",
    "\n",
    "# Cache the audio files so that we don't have to stream them from S3\n",
    "CACHE_DIR = \"data/processed_whisper\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfaa115-9563-4ce7-a390-e2195bb246f9",
   "metadata": {},
   "source": [
    "### Whisper Processor & Preprocessing\n",
    "\n",
    "Prepare tensors for each audio clip to send to model's encoder\n",
    "- Load audio from S3 or disk\n",
    "- Resample to 16 kHz\n",
    "- Compute short-time Fourier transform (STFT)\n",
    "- Convert to Mel scale\n",
    "- Apply log compression\n",
    "- Normalize to match Whisper's training statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9314fab-1ceb-44f1-980f-492a99631123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper Processor & Preprocessing\n",
    "processor = WhisperProcessor.from_pretrained(\n",
    "    WHISPER_MODEL,\n",
    "    language=LANGUAGE,\n",
    "    task=TASK\n",
    ")\n",
    "feature_extractor: WhisperFeatureExtractor = processor.feature_extractor\n",
    "tokenizer: WhisperTokenizer = processor.tokenizer\n",
    "MAX_INPUT_LENGTH = int(MAX_AUDIO_SECONDS * feature_extractor.sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ac1bb-3b01-40b5-a189-745b6601595d",
   "metadata": {},
   "source": [
    "### Load Preprocessed Dataset from EFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b72979a-a8c6-49b7-b567-816138e82ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"/mnt/custom-file-systems/efs/fs-05e9c5047118066bb_fsap-0b12f9aa4c66d5d46/dave_sandbox/full_dataset\")\n",
    "# ds = load_from_disk(\"/mnt/sagemaker-nvme/datasets/filtered_5k_448tok\")\n",
    "# ds = load_from_disk(\"/mnt/custom-file-systems/efs/fs-05e9c5047118066bb_fsap-0b12f9aa4c66d5d46/dave_sandbox/filtered_15k_448tok\")\n",
    "print(ds.column_names)\n",
    "print(ds.features)\n",
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3d9e6-1329-44ea-94e3-7290e8cc5d8d",
   "metadata": {},
   "source": [
    "### Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa4320-c13c-4266-a682-2a73dc2e9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"training/ablation_study.csv\"\n",
    "ablation_study_df = pd.read_csv(csv_path)\n",
    "ablation_study_df.columns = ablation_study_df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "ablation_study_df = ablation_study_df.loc[:, ~ablation_study_df.columns.str.contains(\"^unnamed\")]\n",
    "print(f\"Total runs: {ablation_study_df.shape[0]}\")\n",
    "ablation_study_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f9ccf-4145-455d-8c76-b364a97eb697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to \"To Do\"\n",
    "todo_df = ablation_study_df[ablation_study_df[\"status\"].str.lower().isin([\"to do\"])]\n",
    "todo_df = todo_df.reset_index(drop=True)\n",
    "print(f\"{todo_df.shape[0]} runs ready to launch.\")\n",
    "todo_df[[\"run\", \"peft\", \"num_epochs\", \"learning_rate\", \"warmup_steps\", \"r\", \"alpha\", \"dropout\", \"target_layers\", \"lr_scheduler_type\", \"optimizer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104bf692-89fb-4218-b3d7-af003dc17614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_config(row):\n",
    "    \"\"\"\n",
    "    Convert one CSV row into a structured training config dict\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"run_id\": int(row.run),\n",
    "        \"peft_method\": row.peft.lower(),\n",
    "        \"target_modules\": [m.strip() for m in str(row.target_layers).split(\",\")],\n",
    "        \"learning_rate\": row.learning_rate,\n",
    "        \"num_epochs\": int(row.num_epochs),\n",
    "        \"batch_size\": int(row.batch_size),\n",
    "        \"load_in_4bit\": bool(row.load_in_4bit),\n",
    "        \"rank_r\": None if pd.isna(row.r) else int(row.r) if str(row.r).isdigit() else row.r,\n",
    "        \"lora_alpha\": row.alpha,\n",
    "        \"dropout\": row.dropout,\n",
    "        \"weight_decay\": row.weight_decay,\n",
    "        \"warmup_steps\": int(row.warmup_steps),\n",
    "        \"optimizer\": row.optimizer.lower(),\n",
    "        \"lr_scheduler_type\": row.lr_scheduler_type.lower(),\n",
    "        \"notes\": row.notes if pd.notna(row.notes) else \"\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c75fc-ca88-4910-a07d-195af165e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(config):\n",
    "    bnb_config = None\n",
    "    quant_kwargs = dict(device_map=\"auto\", torch_dtype=torch.float16)\n",
    "\n",
    "    # Quantization setup\n",
    "    if config[\"peft_method\"] == \"qlora\":\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "        )\n",
    "        quant_kwargs[\"quantization_config\"] = bnb_config\n",
    "\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\", **quant_kwargs)\n",
    "    # model.gradient_checkpointing_enable()\n",
    "\n",
    "    if config[\"peft_method\"] == \"qlora\":\n",
    "        model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "    # Sanitize numeric values before building PEFT config\n",
    "    safe_r = int(config.get(\"rank_r\", 16))\n",
    "    safe_alpha = make_json_safe(config.get(\"lora_alpha\", 32))\n",
    "    safe_dropout = make_json_safe(config.get(\"dropout\", 0.05))\n",
    "    safe_target_modules = make_json_safe(config.get(\"target_modules\", [\"q_proj\", \"k_proj\", \"v_proj\"]))\n",
    "\n",
    "    # Define PEFT config\n",
    "    if config[\"peft_method\"] in [\"lora\", \"qlora\", \"dora\"]:\n",
    "        peft_cfg = LoraConfig(\n",
    "            r=safe_r,\n",
    "            lora_alpha=safe_alpha,\n",
    "            lora_dropout=safe_dropout,\n",
    "            bias=\"none\",\n",
    "            target_modules=safe_target_modules,\n",
    "            use_dora=config[\"peft_method\"] == \"dora\",\n",
    "        )\n",
    "\n",
    "    elif config[\"peft_method\"] == \"adalora\":\n",
    "        peft_cfg = AdaLoraConfig(\n",
    "            init_r=int(12),\n",
    "            target_r=int(8),\n",
    "            beta1=0.85,\n",
    "            beta2=0.85,\n",
    "            tinit=int(200),\n",
    "            tfinal=int(1000),\n",
    "            deltaT=int(10),\n",
    "            lora_alpha=safe_alpha,\n",
    "            lora_dropout=safe_dropout,\n",
    "            target_modules=safe_target_modules,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported PEFT method: {config['peft_method']}\")\n",
    "\n",
    "    model = get_peft_model(model, peft_cfg)\n",
    "    model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Loaded {config['peft_method']} model for run #{config['run_id']}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c535aadf-2ccb-46ed-b463-bcd838a7493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_json_safe(x):\n",
    "    \"\"\"\n",
    "    Convert numpy or pandas scalar types to native Python types\n",
    "    \"\"\"\n",
    "    if isinstance(x, (np.integer,)):\n",
    "        return int(x)\n",
    "    elif isinstance(x, (np.floating,)):\n",
    "        return float(x)\n",
    "    elif isinstance(x, (np.bool_,)):\n",
    "        return bool(x)\n",
    "    elif isinstance(x, (np.ndarray, list, tuple)):\n",
    "        return [make_json_safe(i) for i in x]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e72a3-f885-4599-bb91-81e409ed91a4",
   "metadata": {},
   "source": [
    "### Run Experiment(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff15cea-f1e5-4be9-a7ac-29ac3446d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = 10000  # 5000, 1000\n",
    "N_VAL = 2000  # 1000, 300\n",
    "N_TEST = 2000  # 1000, 300\n",
    "N_TO_PULL = int((N_TRAIN + N_VAL + N_TEST) * 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864c781-b80d-4fa4-bf1b-089190af6f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fast, local filter BEFORE selecting slices\n",
    "MAX_LABEL_TOKENS = 448\n",
    "def is_short(example):\n",
    "    return len(example[\"labels\"]) <= MAX_LABEL_TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b8d89-529a-4408-a79f-68e9f832203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle once\n",
    "oversample_ds = ds.shuffle(seed=5678).select(range(N_TO_PULL))\n",
    "print(f\"Fetched {len(oversample_ds)} clips. Need to check if they are under token limit...\")\n",
    "\n",
    "sample_ds = oversample_ds.filter(lambda x: len(x[\"labels\"]) <= MAX_LABEL_TOKENS, num_proc=1)\n",
    "print(f\"Found {len(sample_ds)} valid clips out of {len(oversample_ds)} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea7bd4-6341-4501-8246-f1c6d80cf954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CACHE_DIR_9K = \"/mnt/sagemaker-nvme/datasets/filtered_5k_448tok\"\n",
    "# os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# CACHE_DIR_9K = \"/mnt/custom-file-systems/efs/fs-05e9c5047118066bb_fsap-0b12f9aa4c66d5d46/dave_sandbox/filtered_9k_448tok\"\n",
    "# os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# sample_ds.save_to_disk(CACHE_DIR_9K)\n",
    "# print(f\"Saved 9K filtered dataset to {CACHE_DIR_9K}\")\n",
    "\n",
    "# CACHE_DIR_15K = \"/mnt/custom-file-systems/efs/fs-05e9c5047118066bb_fsap-0b12f9aa4c66d5d46/dave_sandbox/filtered_15k_448tok\"\n",
    "# os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# sample_ds.save_to_disk(CACHE_DIR_15K)\n",
    "# print(f\"Saved 15K filtered dataset to {CACHE_DIR_15K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408e4d1-5412-4c0b-8976-a41224e2478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a clean subset and split into train/val/test\n",
    "sample_ds_train = sample_ds.select(range(min(N_TRAIN, len(sample_ds))))\n",
    "sample_ds_val = sample_ds.select(range(N_TRAIN, min(N_TRAIN + N_VAL, len(sample_ds))))\n",
    "sample_ds_test = sample_ds.select(range(N_TRAIN + N_VAL, min(N_TRAIN + N_VAL + N_TEST, len(sample_ds))))\n",
    "proc_datasets = DatasetDict({\n",
    "    \"train\": sample_ds_train,\n",
    "    \"val\": sample_ds_val,\n",
    "    \"test\": sample_ds_test,\n",
    "})\n",
    "print(f\"Train: {len(sample_ds_train)} | Val: {len(sample_ds_val)}\")\n",
    "print(proc_datasets[\"train\"])\n",
    "print(proc_datasets[\"val\"])\n",
    "print(proc_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea41f497-97c6-4efc-a1e0-4dc0cc882be0",
   "metadata": {},
   "source": [
    "#### Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a075e-23cc-4b53-949f-244b8693c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run one experiment\n",
    "# row_index = 0\n",
    "# PROJECT_NAME = \"dave/20251028_qlora_run1\"\n",
    "\n",
    "# row_index = 1\n",
    "# PROJECT_NAME = \"dave/20251029_dora_run2\"\n",
    "\n",
    "# row_index = 2\n",
    "# PROJECT_NAME = \"dave/20251029_adalora_run3\"\n",
    "\n",
    "# row_index = 4\n",
    "# PROJECT_NAME = \"dave/20251029_qlora_run5\"\n",
    "\n",
    "# row_index = 5\n",
    "# PROJECT_NAME = \"dave/20251029_qlora_run5\"\n",
    "\n",
    "# row_index = 7\n",
    "# PROJECT_NAME = \"dave/20251029_qlora_run7\"\n",
    "\n",
    "# row_index = 7\n",
    "# PROJECT_NAME = \"dave/20251029_qlora_run7_real7_previous_was6\"\n",
    "\n",
    "# row_index = 8\n",
    "# PROJECT_NAME = \"dave/20251029_dora_run9\"\n",
    "\n",
    "# row_index = 9\n",
    "# PROJECT_NAME = \"dave/20251029_dora_run10\"\n",
    "\n",
    "# row_index = 10\n",
    "# PROJECT_NAME = \"dave/20251031_qlora_run11\"\n",
    "\n",
    "# row_index = 11\n",
    "# PROJECT_NAME = \"dave/20251031_dora_run12\"\n",
    "\n",
    "# row_index = 12\n",
    "# PROJECT_NAME = \"dave/20251031_qlora_run13\"\n",
    "\n",
    "row_index = 13\n",
    "PROJECT_NAME = \"dave/20251031_qlora_run14\"\n",
    "\n",
    "row_config = row_to_config(todo_df.loc[row_index, :])\n",
    "print(\"row_config:\", row_config)\n",
    "model = build_model(row_config)\n",
    "\n",
    "print(\"param dtype:\", next(model.parameters()).dtype)  # expect torch.float16\n",
    "print(\"has 4bit modules:\", any(isinstance(m, bnb.nn.Linear4bit) for m in model.modules()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a78652-4c38-4baa-84de-5fc356f999ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    if isinstance(pred_ids, tuple):\n",
    "        pred_ids = pred_ids[0]\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    return {\"wer\": wer(label_str, pred_str)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e05a1-2cc7-49a7-ab7d-e07d52c38450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(features):\n",
    "    # Inspect model dtype dynamically from the encoder’s first layer\n",
    "    try:\n",
    "        model_dtype = next(model.parameters()).dtype\n",
    "    except Exception:\n",
    "        model_dtype = torch.float32  # fallback\n",
    "\n",
    "    # Stack audio features\n",
    "    input_features = torch.stack([\n",
    "        torch.tensor(f[\"input_features\"], dtype=model_dtype)\n",
    "        for f in features\n",
    "    ])\n",
    "\n",
    "    # Pad and process labels\n",
    "    label_batch = [f[\"labels\"] for f in features]\n",
    "    labels = tokenizer.pad(\n",
    "        {\"input_ids\": label_batch},\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    return {\"input_features\": input_features, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b40b57-111f-4629-97aa-0ecb005fa497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_args(cfg, PROJECT_NAME, MIXED_PRECISION=\"fp16\"):\n",
    "    \"\"\"\n",
    "    Create Seq2SeqTrainingArguments from cfg dict safely,\n",
    "    restoring all essential Whisper fine-tuning defaults.\n",
    "    \"\"\"\n",
    "    valid_keys = inspect.signature(Seq2SeqTrainingArguments).parameters.keys()\n",
    "    filtered = {k: v for k, v in cfg.items() if k in valid_keys}\n",
    "\n",
    "    peft_method = cfg.get(\"peft_method\", \"\").lower()\n",
    "    load_in_4bit = cfg.get(\"load_in_4bit\", False)\n",
    "\n",
    "    # Core run settings\n",
    "    filtered[\"output_dir\"] = f\"./outputs/{PROJECT_NAME}\"\n",
    "    filtered[\"overwrite_output_dir\"] = True\n",
    "\n",
    "    # Batching\n",
    "    filtered[\"per_device_train_batch_size\"] = cfg.get(\"batch_size\", 4)\n",
    "    filtered[\"per_device_eval_batch_size\"] = cfg.get(\"batch_size\", 4)\n",
    "    filtered[\"gradient_accumulation_steps\"] = 4\n",
    "    filtered[\"dataloader_num_workers\"] = 2\n",
    "\n",
    "    # Training loop\n",
    "    filtered[\"num_train_epochs\"] = cfg.get(\"num_epochs\", 5)\n",
    "    filtered[\"learning_rate\"] = cfg.get(\"learning_rate\", 5e-5)\n",
    "    filtered[\"weight_decay\"] = cfg.get(\"weight_decay\", 0.01)\n",
    "    filtered[\"lr_scheduler_type\"] = cfg.get(\"lr_scheduler_type\", \"linear\")\n",
    "    filtered[\"warmup_steps\"] = cfg.get(\"warmup_steps\", 0)\n",
    "\n",
    "    # Evaluation / saving\n",
    "    filtered[\"evaluation_strategy\"] = \"epoch\"\n",
    "    filtered[\"save_strategy\"] = \"epoch\"\n",
    "    filtered[\"eval_accumulation_steps\"] = None\n",
    "    filtered[\"eval_delay\"] = 0\n",
    "    filtered[\"load_best_model_at_end\"] = True\n",
    "    filtered[\"metric_for_best_model\"] = \"wer\"\n",
    "    filtered[\"greater_is_better\"] = False\n",
    "    filtered[\"save_total_limit\"] = 3\n",
    "\n",
    "    # Logging\n",
    "    # NOTE: Need to set logging_strategy == epoch in order to get training loss\n",
    "    filtered[\"logging_strategy\"] = \"epoch\"\n",
    "    filtered[\"report_to\"] = [\"tensorboard\"]\n",
    "    filtered[\"logging_dir\"] = f\"./logs/{PROJECT_NAME}\"\n",
    "    filtered[\"disable_tqdm\"] = False\n",
    "\n",
    "    # Precision / optimization\n",
    "    # Setting fp16 to True for qlora since on Tesla T4\n",
    "    # Setting both fp16, bf16 to False forces plain float32\n",
    "    filtered[\"fp16\"] = True\n",
    "    filtered[\"bf16\"] = False\n",
    "    filtered[\"gradient_checkpointing\"] = False  # Checkpointing re-computes every forward pass on the backward step\n",
    "    filtered[\"predict_with_generate\"] = True  # Need True in order to calc validation WER during training\n",
    "\n",
    "    # Determinism / reproducibility\n",
    "    filtered[\"seed\"] = 5678\n",
    "    filtered[\"dataloader_pin_memory\"] = True\n",
    "\n",
    "    # Handle for 4-bit quantized QLoRA training\n",
    "    if peft_method == \"qlora\" and load_in_4bit:\n",
    "        filtered[\"optim\"] = \"adamw_bnb_8bit\"  \n",
    "    else:\n",
    "        filtered[\"optim\"] = \"adamw_torch\"\n",
    "\n",
    "    # Adding on 11/1\n",
    "    if cfg.get(\"peft_method\", \"\").lower() == \"dora\":\n",
    "        print(\"[DoRA detected] Disabling gradient clipping and AMP to avoid FP16 unscale errors.\")\n",
    "        filtered[\"max_grad_norm\"] = 0.0\n",
    "        filtered[\"fp16\"] = False \n",
    "        filtered[\"bf16\"] = False\n",
    "    \n",
    "    # Sanitize numeric types for JSON serialization safety\n",
    "    cfg = {k: make_json_safe(v) for k, v in filtered.items()}\n",
    "\n",
    "    return Seq2SeqTrainingArguments(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c10ccb-5a78-4a59-bb01-10903f1d1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = proc_datasets.get(\"train\") or proc_datasets[\"train\"]\n",
    "eval_data = proc_datasets.get(\"val\") or proc_datasets.get(\"validation\") or None\n",
    "print(f\"Train samples: {len(train_data)}\")\n",
    "print(f\"Eval samples: {len(eval_data) if eval_data else 0}\")\n",
    "print(f\"Device: {model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585aa372-4236-422a-99c6-8d4288f15550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bnb_optimizer_and_scheduler(model, args):\n",
    "    \"\"\"Explicitly create the bitsandbytes optimizer\"\"\"\n",
    "    optimizer = AdamW8bit(\n",
    "        model.parameters(),\n",
    "        lr=args.learning_rate,\n",
    "        betas=(0.9, 0.999),\n",
    "        eps=1e-8,\n",
    "        weight_decay=args.weight_decay,\n",
    "    )\n",
    "    scheduler = get_scheduler(\n",
    "        name=args.lr_scheduler_type,\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=args.warmup_steps,\n",
    "        num_training_steps=args.max_steps,\n",
    "    )\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe09aba-eae4-4879-a1ec-57ae07270d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare trainer\n",
    "args = prepare_args(row_config, PROJECT_NAME)\n",
    "optimizer, lr_scheduler = make_bnb_optimizer_and_scheduler(model, args)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, lr_scheduler),\n",
    ")\n",
    "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=1e-4))\n",
    "\n",
    "print(\"Using optimizer:\", trainer.args.optim)\n",
    "print(type(trainer.optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b7b8e-a2ca-4be0-b189-952f0e0eb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for bitsandbytes optimizer missing .train() and .eval()\n",
    "if hasattr(trainer, \"optimizer\"):\n",
    "    def _noop_train(*args, **kwargs):\n",
    "        return None\n",
    "    def _noop_eval(*args, **kwargs):\n",
    "        return None\n",
    "    opt = trainer.optimizer\n",
    "    if not hasattr(opt, \"train\"):\n",
    "        opt.train = _noop_train\n",
    "    if not hasattr(opt, \"eval\"):\n",
    "        opt.eval = _noop_eval\n",
    "    if hasattr(opt, \"optimizer\"):\n",
    "        inner_opt = opt.optimizer\n",
    "        if not hasattr(inner_opt, \"train\"):\n",
    "            inner_opt.train = _noop_train\n",
    "        if not hasattr(inner_opt, \"eval\"):\n",
    "            inner_opt.eval = _noop_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6761a5-2d67-4fe1-9273-4f2a17d4f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "train_result = trainer.train()\n",
    "print(train_result)\n",
    "\n",
    "# Save LoRA adapter (PEFT) weights (usually to ./results or ./output_dir)\n",
    "trainer.save_model()\n",
    "\n",
    "# Save tokenizer and processor\n",
    "SAVE_DIR = f\"{PROJECT_NAME}/for_hf\"\n",
    "processor.feature_extractor.save_pretrained(SAVE_DIR)\n",
    "processor.save_pretrained(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a47932-2052-47f4-b66a-7e6b95b3429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a fully merged model, loadable with pipeline() without PeFT\n",
    "MERGED_SAVE_DIR = f\"{PROJECT_NAME}/merged\"\n",
    "\n",
    "# Merge LoRA → base weights\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "# Save merged model in the same structure\n",
    "merged_model.save_pretrained(MERGED_SAVE_DIR)\n",
    "processor.feature_extractor.save_pretrained(MERGED_SAVE_DIR)\n",
    "processor.save_pretrained(MERGED_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc4038a-d91c-45f0-8adf-bb66684e0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chart loss + WER\n",
    "logs_df = pd.DataFrame(trainer.state.log_history)\n",
    "train_logs = logs_df.dropna(subset=[\"loss\"])\n",
    "eval_logs = logs_df.dropna(subset=[\"eval_loss\"])\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Left axis: Losses\n",
    "ax1.plot(train_logs[\"epoch\"], train_logs[\"loss\"], label=\"Training Loss\", color=\"tab:blue\", linewidth=2)\n",
    "ax1.plot(eval_logs[\"epoch\"], eval_logs[\"eval_loss\"], label=\"Validation Loss\", color=\"tab:orange\", linewidth=2, marker=\"o\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.tick_params(axis=\"y\")\n",
    "# ax1.set_ylim(bottom=-0.10)\n",
    "\n",
    "# Right axis: WER\n",
    "ax2 = ax1.twinx()\n",
    "if \"eval_wer\" in eval_logs.columns:\n",
    "    ax2.plot(eval_logs[\"epoch\"], eval_logs[\"eval_wer\"], label=\"Validation WER\", color=\"tab:red\", linewidth=2, marker=\"x\", linestyle=\"--\")\n",
    "    ax2.set_ylabel(\"Word Error Rate (WER)\", rotation=270, labelpad=15)\n",
    "    ax2.tick_params(axis=\"y\")\n",
    "\n",
    "# Shared legend & grid\n",
    "plt.title(\"Training and Validation Metrics over Epochs\", fontsize=14, fontweight=\"bold\", pad=40)\n",
    "ax1.grid(True, which=\"both\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "fig.legend(\n",
    "    lines + lines2,\n",
    "    labels + labels2,\n",
    "    loc=\"upper center\",\n",
    "    ncol=3,\n",
    "    bbox_to_anchor=(0.5, 0.88),\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "# Combine legends from both axes\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32daff96-8a69-4a11-b70b-2eba59edae0e",
   "metadata": {},
   "source": [
    "### Evaluation and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11124ee9-94fc-432e-8244-57573bfa7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on Test Split\n",
    "test_metrics = {}\n",
    "if \"test\" in proc_datasets:\n",
    "    test_metrics = trainer.evaluate(proc_datasets[\"test\"], metric_key_prefix=\"test\")\n",
    "    print(test_metrics)\n",
    "else:\n",
    "    print(\"No test split available in proc_datasets. Skipping.\")\n",
    "\n",
    "# Save metrics\n",
    "os.makedirs(\"metrics\", exist_ok=True)\n",
    "now = dt.datetime.utcnow().strftime(\"%Y-%m-%d%H:%M:%S\")\n",
    "fp = f\"metrics/results_{now}.json\"\n",
    "with open(fp, \"w\") as f:\n",
    "    json.dump({\"eval\": trainer.state.log_history, \"test\": test_metrics}, f, indent=2)\n",
    "print(f\"Saved metrics to {fp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42489c3e-967b-4ba9-9078-1c0c02288061",
   "metadata": {},
   "source": [
    "### Push finetuned to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d555a-297f-4e5f-a021-ddf3b383423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, login, whoami\n",
    "\n",
    "login(token=\"FILL_ME_IN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f54f4f9-dd45-46f1-b44d-5d05974279cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d16bf-1db1-40da-b0ae-a6952ca1921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO_PUSH_DIR = \"dave/20251031_qlora_run13/merged\"\n",
    "TO_PUSH_DIR = \"dave/20251031_qlora_run14/merged\"\n",
    "api.upload_folder(\n",
    "    folder_path=TO_PUSH_DIR,\n",
    "    repo_id=\"MIDS-Choate-Kuruppu-Russell/aging-in-place-whisper\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
